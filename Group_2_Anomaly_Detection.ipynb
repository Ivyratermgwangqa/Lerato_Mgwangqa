{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPi5t6jEcQJtsFTiNjlXHuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivyratermgwangqa/Lerato_Mgwangqa/blob/main/Group_2_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the core libraries not pre-installed on Colab\n",
        "!pip install xgboost\n",
        "!pip install shap\n",
        "!pip install imbalanced-learn  # Crucial for SMOTE\n",
        "!pip install kaggle           # If you plan to download datasets directly from Kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kovCgVWFsbId",
        "outputId": "904c1882-9ef3-4bd0-b918-58e68efcb98b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.1)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Core Data Handling & Computation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Data Preprocessing & Evaluation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix,\n",
        "                             classification_report, RocCurveDisplay)\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Handling Class Imbalance (CRITICAL FOR THIS PROJECT)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import make_pipeline as imblearn_make_pipeline\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Explainable AI (XAI)\n",
        "import shap\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# System & Utilities\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Suppress warnings for a cleaner output\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4crwC77rsnkg",
        "outputId": "6191bd8c-2029-4828-eb2f-94704a91c4c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1W85HkQyswrH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "7jpHO_GUq-vU",
        "outputId": "f6110e32-e5a6-4f19-cf8d-a303ce57c06e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemError",
          "evalue": "GPU device not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-119228364.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'/device:GPU:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mSystemError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU device not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found GPU at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemError\u001b[0m: GPU device not found"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b42f7da1"
      },
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dhoogla/cicdarknet2020\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zoKhWrUOuhVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c782473e"
      },
      "source": [
        "# Task\n",
        "Load the \"CIC-Darknet2020\" dataset downloaded from Kaggle into a pandas DataFrame and display the first 5 rows, data types, and descriptive statistics. The dataset is located at the path printed in the output of the cell with id \"1W85HkQyswrH\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b15105c3"
      },
      "source": [
        "## Identify data files\n",
        "\n",
        "### Subtask:\n",
        "List the files in the downloaded directory to understand the dataset structure and identify the relevant data file(s).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00e022b1"
      },
      "source": [
        "**Reasoning**:\n",
        "List the files in the downloaded directory to understand the dataset structure and identify the relevant data file(s).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6a63c4"
      },
      "source": [
        "import os\n",
        "\n",
        "# List the files in the downloaded directory\n",
        "files_in_directory = os.listdir(path)\n",
        "\n",
        "# Print the list of files and directories\n",
        "print(\"Files in the dataset directory:\")\n",
        "for file in files_in_directory:\n",
        "    print(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "898b9286"
      },
      "source": [
        "## Load data\n",
        "\n",
        "### Subtask:\n",
        "Load the main data file into a pandas DataFrame.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd610596"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the parquet file into a pandas DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "427620c3"
      },
      "source": [
        "import os\n",
        "\n",
        "# Construct the full path to the parquet file\n",
        "file_path = os.path.join(path, 'cicdarknet2020.parquet')\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "df = pd.read_parquet(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ee0a286"
      },
      "source": [
        "## Inspect data\n",
        "\n",
        "### Subtask:\n",
        "Display the first few rows and check the data types and basic statistics to get an initial understanding of the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b06c0119"
      },
      "source": [
        "**Reasoning**:\n",
        "Display the first few rows, data types, and basic statistics of the DataFrame to understand its structure and content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f126f0b"
      },
      "source": [
        "display(df.head())\n",
        "display(df.info())\n",
        "display(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a8e6bd"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The dataset is stored in a parquet file named `cicdarknet2020.parquet`.\n",
        "*   The loaded DataFrame contains 103,121 entries and 79 columns.\n",
        "*   The dataset includes numerical columns with various integer and float data types, and likely object type columns for the labels.\n",
        "*   There are no missing values in any of the columns.\n",
        "*   The dataset contains two label columns: 'Label' and 'Label.1'.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Further analysis should investigate the meaning and relationship between the two label columns.\n",
        "*   The presence of various numerical features suggests the need for scaling or normalization before using some machine learning algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple test to verify XGBoost and SHAP work\n",
        "print(\"Testing XGBoost...\")\n",
        "X, y = np.random.rand(100, 5), np.random.randint(0, 2, 100) # Dummy data\n",
        "xgb_model = xgb.XGBClassifier(tree_method='gpu_hist') # Use GPU for training!\n",
        "xgb_model.fit(X, y)\n",
        "print(\"XGBoost model trained successfully!\")\n",
        "\n",
        "print(\"\\nTesting SHAP...\")\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values = explainer.shap_values(X)\n",
        "print(f\"SHAP values calculated. Shape: {np.array(shap_values).shape}\")\n",
        "print(\"✅ Environment setup is complete and functional!\")"
      ],
      "metadata": {
        "id": "oDgpB4VWuxJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5vbxiKYu3-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "057d9d35"
      },
      "source": [
        "# Assuming the label is in a column called 'Label'\n",
        "# Check the distribution of the target variable ('Label')\n",
        "print(\"Target Variable Distribution:\")\n",
        "label_counts = df['Label'].value_counts()\n",
        "print(label_counts)\n",
        "\n",
        "# Visualize the class distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(label_counts.index.astype(str), label_counts.values)\n",
        "plt.title('Class Distribution in Sample Data')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Check the ratio of benign to malicious traffic\n",
        "malicious_ratio = (df['Label'] != 'Benign').sum() / len(df)  # Adjust 'Benign' as needed\n",
        "print(f\"\\nRatio of malicious flows: {malicious_ratio:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acbd04ab"
      },
      "source": [
        "# Check for missing values in the entire DataFrame\n",
        "print(\"Missing values per column:\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0]) # Only show columns with missing values\n",
        "\n",
        "# Visualize missing data (if any)\n",
        "if missing_values.sum() > 0:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(df.isnull(), cbar=False, yticklabels=False)\n",
        "    plt.title('Heatmap of Missing Data')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No missing values found in the sampled data!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d82ac2a8"
      },
      "source": [
        "# Example: Drop columns with all missing values\n",
        "df_clean = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Example: Drop high-cardinality or identifier columns (adjust list as needed)\n",
        "columns_to_drop = ['Src IP', 'Dst IP', 'Src Port', 'Dst Port', 'Timestamp']\n",
        "df_clean = df_clean.drop(columns=[col for col in columns_to_drop if col in df_clean.columns])\n",
        "\n",
        "print(f\"Original shape: {df.shape}\")\n",
        "print(f\"New shape after dropping columns: {df_clean.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2839bbe2"
      },
      "source": [
        "# Fill numerical columns with median (more robust to outliers)\n",
        "numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
        "df_clean[numerical_cols] = df_clean[numerical_cols].fillna(df_clean[numerical_cols].median())\n",
        "\n",
        "# Fill categorical columns with mode\n",
        "categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    df_clean[col] = df_clean[col].fillna(df_clean[col].mode()[0])\n",
        "\n",
        "# Verify no missing values remain\n",
        "print(\"Missing values after imputation:\")\n",
        "print(df_clean.isnull().sum().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e16f1075"
      },
      "source": [
        "# Check for infinite values\n",
        "print(\"Number of infinite values per column:\")\n",
        "# Select only numerical columns before applying isinf\n",
        "numerical_cols = df_clean.select_dtypes(include=np.number).columns\n",
        "infinite_values = df_clean[numerical_cols].apply(lambda x: np.isinf(x).sum())\n",
        "print(infinite_values[infinite_values > 0])\n",
        "\n",
        "# Replace infinite values with a large number (e.g., the maximum value in the column or a predefined large number)\n",
        "# Here, we'll replace with the maximum value of each column to avoid arbitrary large numbers\n",
        "for col in infinite_values[infinite_values > 0].index:\n",
        "    max_val = df_clean[col][np.isfinite(df_clean[col])].max()\n",
        "    df_clean[col] = df_clean[col].replace([np.inf, -np.inf], max_val)\n",
        "\n",
        "# Verify no infinite values remain\n",
        "print(\"\\nNumber of infinite values after handling:\")\n",
        "print(df_clean[numerical_cols].apply(lambda x: np.isinf(x).sum()).sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36eb0ba0"
      },
      "source": [
        "# Perform Sanity Checks: Remove rows with illogical values\n",
        "\n",
        "# Check for negative values in relevant numerical columns\n",
        "print(\"Number of rows with negative values before cleaning:\")\n",
        "negative_duration = (df_clean['Flow Duration'] < 0).sum()\n",
        "negative_fwd_packets = (df_clean['Total Fwd Packet'] < 0).sum()\n",
        "negative_bwd_packets = (df_clean['Total Bwd packets'] < 0).sum()\n",
        "\n",
        "print(f\"  Flow Duration: {negative_duration}\")\n",
        "print(f\"  Total Fwd Packet: {negative_fwd_packets}\")\n",
        "print(f\"  Total Bwd packets: {negative_bwd_packets}\")\n",
        "\n",
        "# Remove rows with negative values in these columns\n",
        "initial_rows = df_clean.shape[0]\n",
        "df_clean = df_clean[df_clean['Flow Duration'] >= 0]\n",
        "df_clean = df_clean[df_clean['Total Fwd Packet'] >= 0]\n",
        "df_clean = df_clean[df_clean['Total Bwd packets'] >= 0]\n",
        "rows_removed = initial_rows - df_clean.shape[0]\n",
        "\n",
        "print(f\"\\nNumber of rows removed during sanity checks: {rows_removed}\")\n",
        "print(f\"New DataFrame shape after sanity checks: {df_clean.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "153ef2e1"
      },
      "source": [
        "# Identify categorical columns\n",
        "categorical_cols = df_clean.select_dtypes(include=['object', 'category']).columns\n",
        "print(\"Categorical columns:\")\n",
        "print(categorical_cols)\n",
        "\n",
        "# Display value counts for categorical columns to understand unique values\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nValue counts for '{col}':\")\n",
        "    print(df_clean[col].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41020aa7"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'Label' column\n",
        "df_clean['Label_Encoded'] = label_encoder.fit_transform(df_clean['Label'])\n",
        "\n",
        "# Display the mapping of original labels to encoded numbers\n",
        "print(\"Label Encoding Mapping:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{label}: {i}\")\n",
        "\n",
        "# Quick dictionary mapping for reference\n",
        "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "print(\"\\nLabel Mapping Dictionary:\", label_mapping)\n",
        "\n",
        "# Verify the encoding by checking the value counts of the new encoded column\n",
        "print(\"\\nValue counts of the encoded target variable:\")\n",
        "print(df_clean['Label_Encoded'].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89e58533"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Identify numerical columns, excluding the encoded target and original label\n",
        "numerical_cols = df_clean.select_dtypes(include=np.number).columns.tolist()\n",
        "# Remove the encoded target column from the list of numerical columns to scale\n",
        "if 'Label_Encoded' in numerical_cols:\n",
        "    numerical_cols.remove('Label_Encoded')\n",
        "\n",
        "# Initialize RobustScaler\n",
        "scaler = RobustScaler()\n",
        "\n",
        "# Apply RobustScaler to the numerical columns\n",
        "df_clean[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
        "\n",
        "print(\"Numerical features have been scaled using RobustScaler.\")\n",
        "display(df_clean.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ca9a970"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "# We use the encoded 'Label_Encoded' column as the target\n",
        "X = df_clean.drop(['Label', 'Label.1', 'Label_Encoded'], axis=1) # Drop original labels and the encoded one to avoid including it in features\n",
        "y = df_clean['Label_Encoded']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# Using stratify=y to maintain the proportion of classes in both train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Original dataset shape: {X.shape}, {y.shape}\")\n",
        "print(f\"Training set shape before SMOTE: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Apply SMOTE to the training data only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"\\nTraining set shape after SMOTE: {X_train_res.shape}, {y_train_res.shape}\")\n",
        "\n",
        "# Check the distribution of the target variable after SMOTE\n",
        "print(\"\\nClass distribution in training set after SMOTE:\")\n",
        "print(pd.Series(y_train_res).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d1cd424"
      },
      "source": [
        "import xgboost as xgb\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize and train an XGBoost model\n",
        "# Use the resampled training data\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_), random_state=42, tree_method='gpu_hist')\n",
        "xgb_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"XGBoost model trained successfully on resampled data.\")\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "# Use the original training data for SHAP explanation (or a representative subset)\n",
        "# Using X_train (before SMOTE) is generally recommended for SHAP explanations\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "print(\"SHAP values calculated.\")\n",
        "\n",
        "# Visualize the feature importance\n",
        "# Use the original feature names from X_train\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\", feature_names=X_train.columns)\n",
        "# plt.title(\"SHAP Feature Importance\") # Remove this line\n",
        "# plt.show() # Remove this line\n",
        "\n",
        "# You can also get a more detailed summary plot\n",
        "# shap.summary_plot(shap_values, X_train)\n",
        "# plt.title(\"SHAP Summary Plot\")\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2a54818"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted') # Use weighted average for multi-class\n",
        "recall = recall_score(y_test, y_pred, average='weighted')     # Use weighted average for multi-class\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')             # Use weighted average for multi-class\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
        "\n",
        "# For multi-class ROC AUC, we can calculate it per class or use macro/weighted average\n",
        "# Let's calculate the weighted average ROC AUC\n",
        "# Need prediction probabilities for roc_auc_score\n",
        "y_pred_proba = xgb_model.predict_proba(X_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted') # Use 'ovr' for one-vs-rest strategy\n",
        "\n",
        "print(\"Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"ROC AUC (Weighted): {roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "display(conf_matrix)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8415c6cc"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "# Initialize and train a Random Forest model\n",
        "# Use the resampled training data\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"Random Forest model trained successfully on resampled data.\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "# For multi-class ROC AUC, need prediction probabilities\n",
        "y_pred_proba_rf = rf_model.predict_proba(X_test)\n",
        "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf, multi_class='ovr', average='weighted')\n",
        "\n",
        "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "class_report_rf = classification_report(y_test, y_pred_rf, target_names=label_encoder.classes_)\n",
        "\n",
        "\n",
        "print(\"\\nRandom Forest Model Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
        "print(f\"Precision: {precision_rf:.4f}\")\n",
        "print(f\"Recall: {recall_rf:.4f}\")\n",
        "print(f\"F1-score: {f1_rf:.4f}\")\n",
        "print(f\"ROC AUC (Weighted): {roc_auc_rf:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix (Random Forest):\")\n",
        "display(conf_matrix_rf)\n",
        "\n",
        "print(\"\\nClassification Report (Random Forest):\")\n",
        "print(class_report_rf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 7. Compare Results\n",
        "# ========================================\n",
        "\n",
        "# Collect the metrics for each model\n",
        "xgb_results = [accuracy, precision, recall, f1, roc_auc]\n",
        "rf_results = [accuracy_rf, precision_rf, recall_rf, f1_rf, roc_auc_rf]\n",
        "\n",
        "metrics = pd.DataFrame([rf_results, xgb_results],\n",
        "                       columns=[\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"ROC-AUC\"],\n",
        "                       index=[\"Random Forest\", \"XGBoost\"])\n",
        "print(metrics)\n",
        "\n",
        "sns.heatmap(metrics, annot=True, cmap=\"Blues\", fmt=\".3f\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VFq_Q3b8mehc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1dbe79e"
      },
      "source": [
        "import shap\n",
        "\n",
        "# Sample only 500 rows to make SHAP faster\n",
        "X_sample = X_train.sample(500, random_state=42)\n",
        "\n",
        "# Explain the Random Forest model's predictions\n",
        "explainer_rf = shap.TreeExplainer(rf_model)\n",
        "shap_values_rf = explainer_rf(X_sample)   # ✅ new API\n",
        "\n",
        "print(\"SHAP values calculated for Random Forest model.\")\n",
        "\n",
        "# Feature importance (bar plot)\n",
        "shap.summary_plot(shap_values_rf, X_sample, plot_type=\"bar\", feature_names=X_sample.columns)\n",
        "\n",
        "# Detailed summary plot (dot plot)\n",
        "shap.summary_plot(shap_values_rf, X_sample)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 8. Prototype Demo - Single Prediction\n",
        "# ========================================\n",
        "\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure consistent X_test for both models\n",
        "try:\n",
        "    if 'X_test' not in globals() or 'y_test' not in globals():\n",
        "        print(\"Re-splitting data to ensure consistent X_test...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "except NameError as e:\n",
        "    print(f\"Error: {e}. Ensure X and y are defined from Step 4.\")\n",
        "    raise\n",
        "\n",
        "# Ensure SHAP JavaScript is initialized (optional for matplotlib backend)\n",
        "shap.initjs()\n",
        "\n",
        "# Create a label encoder for decoding predictions (multi-class: 'Non-Tor', 'NonVPN', 'Tor', 'VPN')\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.classes_ = np.array(['Non-Tor', 'NonVPN', 'Tor', 'VPN'])  # Matches dataset labels\n",
        "\n",
        "# Pick one random row from the test set\n",
        "sample = X_test.iloc[[0]]  # Shape (1, 77)\n",
        "print(\"Sample Flow Metadata:\\n\", sample)\n",
        "\n",
        "# Predict with both models\n",
        "try:\n",
        "    rf_pred = rf_model.predict(sample)\n",
        "    xgb_pred = xgb_model.predict(sample)\n",
        "except NameError as e:\n",
        "    print(f\"Error: {e}. Ensure rf_model and xgb_model are defined from Steps 5-6.\")\n",
        "    raise\n",
        "\n",
        "# Decode predictions to original class names\n",
        "rf_pred_label = label_encoder.inverse_transform(rf_pred)[0]\n",
        "xgb_pred_label = label_encoder.inverse_transform(xgb_pred)[0]\n",
        "\n",
        "print(\"\\nRandom Forest Prediction:\", rf_pred_label)\n",
        "print(\"XGBoost Prediction:\", xgb_pred_label)\n"
      ],
      "metadata": {
        "id": "5weNY_SowklY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 9. Export Results\n",
        "# ========================================\n",
        "\n",
        "import joblib\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Save models\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
        "joblib.dump(xgb_model, \"xgboost_model.pkl\")\n",
        "\n",
        "# Save metrics table\n",
        "metrics.to_csv(\"model_comparison_results.csv\", index=True)\n",
        "\n",
        "# Sample only 500 rows from X_test to make SHAP faster for the summary plot\n",
        "X_test_sample = X_test.sample(500, random_state=42)\n",
        "\n",
        "# Calculate SHAP values for XGBoost on the test sample\n",
        "# Use the explainer created earlier for the XGBoost model\n",
        "xgb_explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values_xgb_test_sample = xgb_explainer(X_test_sample)\n",
        "\n",
        "# Save SHAP summary plots\n",
        "plt.figure()\n",
        "# Use shap_values_rf from the previous cell\n",
        "shap.summary_plot(shap_values_rf, X_sample, feature_names=X_sample.columns, show=False)\n",
        "plt.savefig(\"rf_shap_summary.png\", bbox_inches='tight')\n",
        "\n",
        "plt.figure()\n",
        "# Use the newly calculated SHAP values for XGBoost on the test sample\n",
        "shap.summary_plot(shap_values_xgb_test_sample, X_test_sample, feature_names=X_test_sample.columns, show=False)\n",
        "plt.savefig(\"xgb_shap_summary.png\", bbox_inches='tight')"
      ],
      "metadata": {
        "id": "Vggs2f7DxRV4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}